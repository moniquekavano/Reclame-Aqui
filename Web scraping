import requests
import json
import pandas as pd
import math

company = "SASpnYwh265yUOLl"
company = "Ez23ohvuvTR9UPQs"
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"
session    = requests.session()

##REQUEST INITIAL PAGE
headers_InicialPage  = {"Host"             : "www.reclameaqui.com.br",
                        "User-Agent"       : USER_AGENT,
                        "sec-ch-ua-mobile" : "?0"}

url_InicialPage      = "https://www.reclameaqui.com.br/"
response_InicialPage = session.get(url=url_InicialPage, headers=headers_InicialPage)
    
##REQUEST COMPLAINS
headers_Complains  = {"Host"             : "iosearch.reclameaqui.com.br",
                      "Origin"           : "https://www.reclameaqui.com.br",
                        "User-Agent"       : "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36",
                        "Upgrade-Insecure-Requests": "1",
                        "Sec-Ch-Ua-Platform": "\"macOS\"",
                        "Sec-Ch-Ua": "\"Not/A)Brand\";v=\"8\", \"Chromium\";v=\"126\", \"Google Chrome\";v=\"126\"",
                        "sec-ch-ua-mobile" : "?0",
                        "conection": "keep-alive"}

url_complains      = f"https://iosearch.reclameaqui.com.br/raichu-io-site-search-v1/query/companyComplains/10/0?company={company}"
response_Complains = session.get(url=url_complains, headers=headers_Complains, cookies=response_InicialPage.cookies)

reclamacoes = json.loads(response_Complains.text)
total_complains = reclamacoes['complainResult']['complains']['count']
total_paginas = math.ceil(total_complains / 10)        #math.ceil arredonda para cima
total_paginas = min(total_paginas,50)
print(f"Essa empresa possui {total_complains} reclamações e usaresmos {total_paginas} páginas.")

df_reclamacoes = None

for pagina in range(total_paginas):
    rec_pg = 10 * pagina
    url = f"https://iosearch.reclameaqui.com.br/raichu-io-site-search-v1/query/companyComplains/10/{rec_pg}?company={company}"
    
    #print(f"Processando URL: {url}")
    code = 0 
    while (code != 200):
        response_Complains = session.get(url, headers={"User-Agent": USER_AGENT}, cookies=response_Complains.cookies)
        code = response_Complains.status_code
        if response_Complains.status_code == 200:
            reclamacoes_pagina = response_Complains.json()
            df_reclamacoes_pagina = pd.DataFrame(reclamacoes_pagina['complainResult']['complains']['data'], columns= ['id'])
            df_reclamacoes        = df_reclamacoes_pagina if (df_reclamacoes is None) else pd.concat([df_reclamacoes, df_reclamacoes_pagina], ignore_index=True)
            
            print(f"Página {pagina + 1} processada com sucesso.")            
        else:
            print(f"erro ao carregar página {pagina + 1}")

print(len(df_reclamacoes))

reclamacoes_completas = []

for index, row in df_reclamacoes.iterrows():
    id = row["id"]
    url = f"https://iosite.reclameaqui.com.br/raichu-io-site-v1/complain/public/{id}"

    #print(f"Processando URL: {url}")

    code = 0 
    while (code != 200):

        headers_Complains  = {"Host"             : "iosite.reclameaqui.com.br",
                       "User-Agent"       : "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36",
                        "Upgrade-Insecure-Requests": "1",
                        "Sec-Ch-Ua-Platform": "\"macOS\"",
                        "Sec-Ch-Ua": "\"Not/A)Brand\";v=\"8\", \"Chromium\";v=\"126\", \"Google Chrome\";v=\"126\"",
                        "sec-ch-ua-mobile" : "?0",
                        "conection": "keep-alive"}

        response_Complains = session.get(url, headers=headers_Complains, cookies=response_InicialPage.cookies)

        if response_Complains.status_code == 200:
            reclamacoes_pagina = response_Complains.json()
            title = reclamacoes_pagina['title']
            description = reclamacoes_pagina['description']
            problem_type_name = reclamacoes_pagina.get('problemType', {}).get('name', 'Nome não encontrado')
            user_city = reclamacoes_pagina.get('userCity', 'Cidade não encontrada')
            user_state = reclamacoes_pagina.get('userState', 'Estado não encontrado')
            status = reclamacoes_pagina.get('status', 'Status não encontrado')
            score = reclamacoes_pagina.get('score', 'Score não encontrado')
            evaluation = reclamacoes_pagina.get('evaluation', 'Avaliação não encontrada')
            created = reclamacoes_pagina.get('created', 'Data não encontrada')
            modified = reclamacoes_pagina.get('modified', 'Data não encontrada')
            reclamacoes_completas.append({'title': title, 'description': description, 'type': problem_type_name, 'city': user_city, 'state': user_state, 'satus': status, 'score': score, 'evaluation': evaluation, 'created': created, 'modified': modified})
        else:
            print("tentando ler url: " + url)
            session    = requests.session()
            response_Complains = session.get(url=url_InicialPage, headers=headers_InicialPage)


df_reclamacoes_completas = pd.DataFrame(reclamacoes_completas)
#df_reclamacoes_completas.to_excel('SERENA.xlsx', index=False)
